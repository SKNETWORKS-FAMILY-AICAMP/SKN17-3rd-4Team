import streamlit as st
import json
import os
import requests
import torch
import faiss
import numpy as np
from dotenv import load_dotenv
from urllib.parse import unquote
from datetime import datetime
from sentence_transformers import SentenceTransformer
from transformers import AutoModelForCausalLM, AutoTokenizer

# --- 1. ì´ˆê¸° ì„¤ì • ---
load_dotenv()

st.set_page_config(page_title="AI ìœ¡ì•„ ë„ìš°ë¯¸ ë´‡", layout="centered")

try:
    HIRA_API_SERVICE_KEY = os.environ.get("HIRA_API_SERVICE_KEY") or st.secrets.get("HIRA_API_SERVICE_KEY")
    KAKAO_API_REST_KEY = os.environ.get("KAKAO_API_REST_KEY") or st.secrets.get("KAKAO_API_REST_KEY")
    if not HIRA_API_SERVICE_KEY or not KAKAO_API_REST_KEY:
        raise KeyError
except KeyError:
    st.error("í•„ìˆ˜ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ ë˜ëŠ” Streamlit secretsë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# --- 2. ëª¨ë¸ ë° ë°ì´í„° ë¡œë”© ---
@st.cache_resource
def load_all_models_and_data():
    """RAGì— í•„ìš”í•œ ëª¨ë“  ëª¨ë¸ê³¼ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    HF_EMBED_REPO_ID = "WOOJINIYA/parentcare-bot-bge-m3"
    HF_LLM_REPO_ID = "WOOJINIYA/parentcare-bot-qwen2.5-7b"
    LOCAL_INDEX_PATH = "faiss.index"
    LOCAL_META_PATH = "faiss.meta.json"

    embed_model = SentenceTransformer(HF_EMBED_REPO_ID)
    tokenizer = AutoTokenizer.from_pretrained(HF_LLM_REPO_ID)
    model = AutoModelForCausalLM.from_pretrained(
        HF_LLM_REPO_ID, device_map="auto", torch_dtype=torch.float16, load_in_4bit=True
    )
    
    try:
        index = faiss.read_index(LOCAL_INDEX_PATH)
        with open(LOCAL_META_PATH, "r", encoding="utf-8") as f:
            meta = json.load(f)
    except FileNotFoundError as e:
        st.error(f"í•„ìˆ˜ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}. 'faiss.index'ì™€ 'faiss.meta.json' íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()
        
    return embed_model, tokenizer, model, index, meta["texts"], meta.get("metas")

with st.spinner("AI ëª¨ë¸ê³¼ ìœ¡ì•„ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤... (ìµœì´ˆ ì‹¤í–‰ ì‹œ ì‹œê°„ì´ ë‹¤ì†Œ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
    embed_model, tokenizer, model, index, TEXTS, METAS = load_all_models_and_data()


# --- 3. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ì •ì˜ ---

def generate_text(prompt_text, max_tokens, temperature=0.1):
    """LLMì„ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” í†µí•© í•¨ìˆ˜ (ì˜ë„ë¶„ì„ìš©)"""
    inputs = tokenizer(prompt_text, return_tensors="pt", truncation=True, max_length=4096).to(model.device)
    outputs = model.generate(
        **inputs, max_new_tokens=max_tokens, do_sample=True, temperature=temperature, top_p=0.95
    )
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

def parse_intent_with_ai(user_prompt):
    """ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ 'search' ë˜ëŠ” 'chat'ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³ , ê´€ë ¨ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    search_keywords = ['ì£¼ë³€', 'ì°¾ì•„ì¤˜', 'ì–´ë””', 'ì†Œì•„ê³¼', 'ì‚°ë¶€ì¸ê³¼', 'ì•½êµ­', 'ë³‘ì›']
    if any(keyword in user_prompt for keyword in search_keywords):
        system_prompt = "ì‚¬ìš©ìì˜ ë©”ì‹œì§€ì—ì„œ 'place'ì™€ 'location'ì„ ì¶”ì¶œí•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•´ë¼. 'place'ëŠ” ë³‘ì›, ì•½êµ­, ì†Œì•„ê³¼, ì‚°ë¶€ì¸ê³¼ ë“± ì¥ì†Œ ì¢…ë¥˜ë¥¼ ì˜ë¯¸í•˜ê³  'location'ì€ 'ì„œìš¸ ëŒ€ë°©ë™' ê°™ì€ ì§€ì—­ëª…ì„ ì˜ë¯¸í•œë‹¤. ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ì—†ìœ¼ë©´ nullë¡œ í‘œì‹œí•´ë¼. ì˜ˆì‹œ: {\"place\": \"ì†Œì•„ê³¼\", \"location\": \"ì„œìš¸ ëŒ€ë°©ë™\"}"
        messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}]
        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
        full_response = generate_text(prompt, 128)
        try:
            json_part_start = full_response.find('{')
            json_part_end = full_response.rfind('}') + 1
            if json_part_start != -1 and json_part_end != 0:
                json_part = full_response[json_part_start:json_part_end]
                intent = json.loads(json_part)
                intent['action'] = 'search'
                return intent
            else:
                 return {"action": "chat"}
        except (json.JSONDecodeError, Exception):
            return {"action": "chat"}
    return {"action": "chat"}

# --- ì¥ì†Œ ê²€ìƒ‰ (Kakao & HIRA API) ê´€ë ¨ í•¨ìˆ˜ ---
def geocode_kakao(address):
    endpoint = "https://dapi.kakao.com/v2/local/search/address.json"
    headers = {"Authorization": f"KakaoAK {KAKAO_API_REST_KEY}"}
    params = {'query': address}
    try:
        response = requests.get(endpoint, headers=headers, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        if data['documents']:
            doc = data['documents'][0]
            return float(doc['y']), float(doc['x']), None
        return None, None, f"'{address}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        return None, None, f"ì¹´ì¹´ì˜¤ë§µ API ì˜¤ë¥˜: {e}"

def _search_hira(lat, lon, place_type, endpoint):
    params = {"serviceKey": unquote(HIRA_API_SERVICE_KEY), "xPos": lon, "yPos": lat, "radius": 3000, "_type": "json"}
    try:
        response = requests.get(endpoint, params=params, timeout=10)
        response.raise_for_status()
        items = response.json().get('response', {}).get('body', {}).get('items', {}).get('item', [])
        if not items: return f"ì£¼ë³€ 3km ì´ë‚´ì— ê²€ìƒ‰ëœ '{place_type}'ì´(ê°€) ì—†ìŠµë‹ˆë‹¤."
        
        sorted_items = sorted(items, key=lambda x: float(x.get('distance', 99999)))
        today_weekday = datetime.now().weekday() + 1
        
        response_text = f"âœ… **'{place_type}'** ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤. (ê±°ë¦¬ ìˆœ, ìµœëŒ€ 5ê³³)\n\n"
        for item in sorted_items[:5]:
            response_text += f"**{item['yadmNm']}**\n- ì£¼ì†Œ: {item['addr']}\n"
            telno = item.get('telno', 'ì •ë³´ ì—†ìŒ')
            tel_link = ''.join(filter(str.isdigit, telno)) if telno != 'ì •ë³´ ì—†ìŒ' else ''
            response_text += f"- ì „í™”: [{telno}](tel:{tel_link})\n"
            start_time, close_time = item.get(f'dutyTime{today_weekday}s'), item.get(f'dutyTime{today_weekday}c')
            operating_hours = f"{start_time[:2]}:{start_time[2:]} ~ {close_time[:2]}:{close_time[2:]}" if start_time and close_time else "ì •ë³´ ì—†ìŒ"
            response_text += f"- ì˜¤ëŠ˜ ì˜ì—…ì‹œê°„: {operating_hours} (ë°©ë¬¸ ì „ í™•ì¸ í•„ìˆ˜)\n---\n"
        return response_text
    except Exception as e:
        return f"{place_type} API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

def search_hospitals(lat, lon, place_type):
    return _search_hira(lat, lon, place_type, "http://apis.data.go.kr/B551182/hospInfoServicev2/getHospBasisList")
def search_pharmacies(lat, lon):
    return _search_hira(lat, lon, "ì•½êµ­", "http://apis.data.go.kr/B551182/pharmacyInfoService/getParmacyBasisList")

def handle_search(intent):
    location_name = intent.get("location")
    place_type = intent.get("place", "ë³‘ì›")
    if not location_name: return "ì–´ë”” ì£¼ë³€ì—ì„œ ì°¾ì•„ë“œë¦´ê¹Œìš”? 'ì„œìš¸ ëŒ€ë°©ë™'ì²˜ëŸ¼ ì§€ì—­ ì´ë¦„ì„ ì•Œë ¤ì£¼ì„¸ìš”."
    lat, lon, error_message = geocode_kakao(location_name)
    if error_message: return f"âš ï¸ ìœ„ì¹˜ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:\n\n`{error_message}`"
    if lat and lon:
        return search_pharmacies(lat, lon) if "ì•½êµ­" in place_type else search_hospitals(lat, lon, place_type)


SYSTEM_PROMPT_RAG = """
# ì—­í•  ì •ì˜
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ë¶€ëª¨ë“¤ì„ ìœ„í•œ **ìœ¡ì•„ ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ ì±—ë´‡**ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ë¶€ëª¨ë“¤ì˜ ìœ¡ì•„ ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•´ ê°€ì¥ ì‹ ë¢°í•  ìˆ˜ ìˆê³  ì‹¤ìš©ì ì¸ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. í•­ìƒ ë”°ëœ»í•˜ê³ , ê³µê°ì ì´ë©°, ê²©ë ¤í•˜ëŠ” íƒœë„ë¥¼ ìœ ì§€í•˜ì„¸ìš”.

# ë‹µë³€ ìƒì„± í”„ë¡œì„¸ìŠ¤
ë‹¹ì‹ ì€ ë‹¤ìŒì˜ ë…¼ë¦¬ì  ìˆœì„œì— ë”°ë¼ ë‹µë³€ ëª¨ë“œë¥¼ ê²°ì •í•˜ê³  ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.

1.  **[CASE C í™•ì¸]:** ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ì´ì „ ëŒ€í™”ì— ëŒ€í•œ ë‹¨ìˆœ í™•ì¸, ê°ì‚¬, ì§§ì€ ì˜ê²¬ ë“±ì¸ì§€ ë¨¼ì € í™•ì¸í•©ë‹ˆë‹¤. ë§Œì•½ ê·¸ë ‡ë‹¤ë©´, `[C. ì§§ì€ ëŒ€í™”í˜• ë‹µë³€]` ê·œì¹™ì— ë”°ë¼ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€ë‹µí•˜ê³  í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.
2.  **[CASE A í™•ì¸]:** ì§ˆë¬¸ì´ ì •ë³´ ì œê³µì„ ìš”êµ¬í•˜ë©° 'ì°¸ê³  ìë£Œ'ê°€ ìˆëŠ” ê²½ìš°, `[A. RAG ê¸°ë°˜ ë‹µë³€ í˜•ì‹]`ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
3.  **[CASE B ì ìš©]:** ìœ„ ë‘ ê²½ìš°ì— í•´ë‹¹í•˜ì§€ ì•Šìœ¼ë©´, `[B. ì¼ë°˜ ë‹µë³€ í˜•ì‹]`ì— ë”°ë¼ ë‹¹ì‹ ì˜ ì§€ì‹ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.

---

# [A. RAG ê¸°ë°˜ ë‹µë³€ í˜•ì‹]
'ì°¸ê³  ìë£Œ'ê°€ ìˆì„ ë•Œ ì‚¬ìš©í•˜ëŠ” ì—„ê²©í•œ ì¶œë ¥ í˜•ì‹ì…ë‹ˆë‹¤. ì•„ë˜ 4ê°œ ì„¹ì…˜ì„ **ì •í™•íˆ** ì§€ì¼œì„œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.

1.  **âœ… í•µì‹¬ ìš”ì•½:**
    * ì§ˆë¬¸ì— ëŒ€í•œ ê°€ì¥ ì¤‘ìš”í•œ ë‹µë³€ì„ 3ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
2.  **ğŸ‘¶ ë‹¨ê³„ë³„ ê°€ì´ë“œ:**
    * ë¶€ëª¨ê°€ ì‹¤ì œë¡œ ë”°ë¼ í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ í–‰ë™ ì§€ì¹¨ì„ 3~10ê°œì˜ ë²ˆí˜¸ ëª©ë¡ìœ¼ë¡œ ì œì‹œí•©ë‹ˆë‹¤. ê° í•­ëª©ì€ ì¤‘ë³µëœ ë¬¸ì¥ì´ ì—†ê²Œ í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•©ë‹ˆë‹¤.
3.  **ğŸ“Œ ê·¼ê±°:**
    * ë‹µë³€ì˜ ê·¼ê±°ê°€ ëœ 'ì°¸ê³  ìë£Œ'ì˜ ì¶œì²˜(`id / title / category`)ë¥¼ ëª…ì‹œí•©ë‹ˆë‹¤. ë™ì¼í•œ ì¶œì²˜ëŠ” í•œ ë²ˆë§Œ ì–¸ê¸‰í•©ë‹ˆë‹¤.
4.  **âš ï¸ ì£¼ì˜/ë©´ì±…:**
    * ì˜í•™ì  ì¡°ì–¸ì˜ í•œê³„ë¥¼ ëª…ì‹œí•˜ê³ , ì „ë¬¸ê°€ ìƒë‹´ì˜ ì¤‘ìš”ì„±ì„ 2ë¬¸ì¥ ì´ë‚´ë¡œ ê°•ì¡°í•©ë‹ˆë‹¤. ë§¤ë²ˆ ë‹¤ë¥¸ ë¬¸ì¥ìœ¼ë¡œ í‘œí˜„í•˜ì„¸ìš”.

---

# [B. ì¼ë°˜ ë‹µë³€ í˜•ì‹]
'ì°¸ê³  ìë£Œ'ê°€ ì—†ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” ìœ ì—°í•œ ì¶œë ¥ í˜•ì‹ì…ë‹ˆë‹¤.

1.  **ê³µê°ì  ë„ì…:**
    * "ë§ì´ í˜ë“œì‹œê² ì–´ìš”.", "ë§ì€ ë¶€ëª¨ë‹˜ë“¤ì´ ê²ªëŠ” ê³ ë¯¼ì´ì—ìš”." ë“± ì‚¬ìš©ìì˜ ìƒí™©ì— ê³µê°í•˜ëŠ” ë¬¸ì¥ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”.
2.  **ì²´ê³„ì ì¸ ì¡°ì–¸:**
    * **ì†Œì œëª©**, **ê¸€ë¨¸ë¦¬ ê¸°í˜¸(â€¢)**, **ì´ëª¨ì§€(ğŸ’¡, ğŸ§¸ ë“±)**ë¥¼ ììœ ë¡­ê²Œ í™œìš©í•˜ì—¬ ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ëª…í™•í•˜ê³  ì½ê¸° ì‰½ê²Œ ì œì‹œí•˜ì„¸ìš”. ì •ë³´ì˜ ë‚˜ì—´ì´ ì•„ë‹Œ, ì‹¤ì œ ë„ì›€ì´ ë˜ëŠ” íŒ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.
3.  **ì „ë¬¸ê°€ ì¡°ì–¸ ê¶Œì¥:**
    * ë‹µë³€ ë§ˆì§€ë§‰ì—ëŠ” "ì•„ì´ì˜ ìƒíƒœê°€ ì§€ì†ë˜ê±°ë‚˜ ê±±ì •ë˜ì‹ ë‹¤ë©´, ì†Œì•„ê³¼ ì „ë¬¸ì˜ì™€ ìƒë‹´í•´ë³´ì‹œëŠ” ê²ƒì´ ê°€ì¥ ì •í™•í•©ë‹ˆë‹¤."ì™€ ê°™ì´ ì „ë¬¸ê°€ ìƒë‹´ì„ ê¶Œì¥í•˜ëŠ” ë‚´ìš©ì„ ë¶€ë“œëŸ½ê²Œ í¬í•¨í•˜ì—¬ ì±…ì„ì„ ëª…í™•íˆ í•˜ì„¸ìš”.

---

# [C. ì§§ì€ ëŒ€í™”í˜• ë‹µë³€]
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ì•„ë˜ì™€ ê°™ì„ ê²½ìš°, Aë‚˜ B í˜•ì‹ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ìì—°ìŠ¤ëŸ¬ìš´ ì¼ìƒ ëŒ€í™”ì²˜ëŸ¼ í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ì§§ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤.
- ì´ì „ ëŒ€í™” ë‚´ìš©ì— ëŒ€í•œ ë‹¨ìˆœ í™•ì¸ (ì˜ˆ: "ë°©ê¸ˆ ëª‡ ë„ë¼ê³  í–ˆì§€?", "ì•„ê¹Œ ë§í•œ ì²«ë²ˆì§¸ ë°©ë²•ì´ ë­ì˜€ì–´?")
- ê°ì‚¬ í‘œí˜„ (ì˜ˆ: "ê³ ë§ˆì›Œ", "ë„ì›€ì´ ëì–´")
- ê°„ë‹¨í•œ ì¸ì‚¬ë‚˜ ì§§ì€ ì˜ê²¬ (ì˜ˆ: "ê·¸ë ‡êµ¬ë‚˜", "ì•Œê² ì–´")

---

# ê³µí†µ ê·œì¹™ ë° ì œì•½ì‚¬í•­ (ëª¨ë“  ë‹µë³€ì— ì ìš©)
* **ì–´ì¡°:** í•­ìƒ ì¹œì ˆí•˜ê³ , ê¸ì •ì ì´ë©°, ë¶€ëª¨ë¥¼ ì§€ì§€í•˜ëŠ” ê²©ë ¤ì˜ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
* **ì˜ë£Œì  ì¡°ì–¸ ê¸ˆì§€:** ë‹¹ì‹ ì€ ì˜ì‚¬ê°€ ì•„ë‹™ë‹ˆë‹¤. í™•ì •ì ì¸ ì§ˆë³‘ì„ ì§„ë‹¨í•˜ê±°ë‚˜ íŠ¹ì • ì•½ë¬¼ì„ ì¶”ì²œí•˜ëŠ” ë“± ì˜ë£Œ ì „ë¬¸ê°€ì˜ ì˜ì—­ì„ ì ˆëŒ€ ì¹¨ë²”í•˜ì§€ ë§ˆì„¸ìš”.
* **ì‘ê¸‰ ìƒí™©:** ì‚¬ìš©ìì˜ ì§ˆë¬¸ ë‚´ìš©ì— ê³ ì—´, í˜¸í¡ ê³¤ë€, ì˜ì‹ ì €í•˜, ê²½ë ¨, ì‹¬í•œ íƒˆìˆ˜ ë“± **ì‘ê¸‰ ì§•í›„**ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´, ë‹¤ë¥¸ ì •ë³´ë³´ë‹¤ **ì¦‰ì‹œ 119 ì‹ ê³  ë˜ëŠ” ì‘ê¸‰ì‹¤ ë°©ë¬¸**ì„ ìµœìš°ì„ ìœ¼ë¡œ ì•ˆë‚´í•˜ì„¸ìš”.
* **ì–¸ì–´:** ë°˜ë“œì‹œ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•©ë‹ˆë‹¤. ì „ë¬¸ ìš©ì–´ ì‚¬ìš©ì„ ìµœì†Œí™”í•˜ì„¸ìš”.
"""

def retrieve(query, top_k=5):
    q_emb = embed_model.encode([query], normalize_embeddings=True).astype("float32")
    _, indices = index.search(q_emb, top_k)
    return [{"meta": METAS[i], "text": TEXTS[i]} for i in indices[0]]

def build_context(docs):
    context = []
    # ì¤‘ë³µëœ ì¶œì²˜ë¥¼ ì œê±°í•˜ê¸° ìœ„í•œ set
    seen_ids = set()
    for doc in docs:
        meta = doc.get("meta", {})
        doc_id = meta.get('id', 'N/A')
        # idê°€ ì—†ê±°ë‚˜ ì´ë¯¸ ë³¸ idì¸ ê²½ìš° ê±´ë„ˆë›°ê¸°
        if doc_id == 'N/A' or doc_id in seen_ids:
            continue
        context.append(f"ì¶œì²˜: {doc_id} | ì œëª©: {meta.get('title', 'N/A')}\n{doc.get('text', '')}")
        seen_ids.add(doc_id)
    return "\n\n".join(context)

def ask_rag(conversation_history):
    """
    [ìˆ˜ì •ëœ ë²„ì „]
    ìˆœìˆ˜í•œ ëŒ€í™” ê¸°ë¡ê³¼ RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¶„ë¦¬í•˜ì—¬ LLMì— ëª…í™•í•œ ì§€ì‹œë¥¼ ë‚´ë¦½ë‹ˆë‹¤.
    """
    # RAG ê²€ìƒ‰ì„ ìœ„í•´ ìµœì‹  ì‚¬ìš©ì ì§ˆë¬¸ ì¶”ì¶œ
    user_prompt = conversation_history[-1]["content"]
    docs = retrieve(user_prompt)
    context_str = build_context(docs)

    # [ìˆ˜ì •] LLMì— ì „ë‹¬í•  ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒˆë¡œ êµ¬ì„±
    # 1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    # 2. ìˆœìˆ˜í•œ ì´ì „ ëŒ€í™” ê¸°ë¡
    # 3. ë§ˆì§€ë§‰ì— RAG ì»¨í…ìŠ¤íŠ¸ì™€ ìƒˆë¡œìš´ ì§ˆë¬¸ì„ í•¨ê»˜ ë‹´ì€ ëª…í™•í•œ ì§€ì‹œë¬¸
    messages_for_llm = [
        {"role": "system", "content": SYSTEM_PROMPT_RAG}
    ]

    # ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ê·¸ëŒ€ë¡œ ì¶”ê°€
    # ë§ˆì§€ë§‰ ì‚¬ìš©ì ì§ˆë¬¸ì€ ì œì™¸í•˜ê³  ì¶”ê°€ (ë‚˜ì¤‘ì— í¬ë§·íŒ…í•´ì„œ ë„£ì„ ê²ƒì´ë¯€ë¡œ)
    messages_for_llm.extend(conversation_history[:-1])

    # [ë³€ê²½] RAG ì»¨í…ìŠ¤íŠ¸ì™€ ìµœì‹  ì§ˆë¬¸ì„ ê²°í•©í•œ ëª…í™•í•œ ì§€ì‹œ í”„ë¡¬í”„íŠ¸ ìƒì„±
    # ì°¸ê³  ìë£Œê°€ ë¹„ì–´ìˆëŠ” ê²½ìš°(RAG ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°)ë¥¼ ëŒ€ë¹„
    if context_str.strip():
        augmented_prompt = (
            f"ì•„ë˜ 'ì°¸ê³  ìë£Œ'ì™€ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•´ì¤˜.\n\n"
            f"--- ì°¸ê³  ìë£Œ ---\n{context_str}\n------------------\n\n"
            f"ì§ˆë¬¸: {user_prompt}"
        )
    else:
        # RAG ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´, ì´ì „ ëŒ€í™” ë‚´ìš©ë§Œ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ë„ë¡ ìš”ì²­
        augmented_prompt = (
            f"ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•´ì¤˜.\n\n"
            f"ì§ˆë¬¸: {user_prompt}"
        )

    # ë§ˆì§€ë§‰ user ë©”ì‹œì§€ë¡œ ì§€ì‹œ í”„ë¡¬í”„íŠ¸ë¥¼ ì¶”ê°€
    messages_for_llm.append({"role": "user", "content": augmented_prompt})

    # ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„± ë° LLM í˜¸ì¶œ
    prompt = tokenizer.apply_chat_template(messages_for_llm, tokenize=False, add_generation_prompt=True)
    
    raw_inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
    outputs = model.generate(**raw_inputs, max_new_tokens=1024, do_sample=True, temperature=0.2, top_p=0.95)
    
    # í”„ë¡¬í”„íŠ¸ë¥¼ ì œì™¸í•œ ìˆœìˆ˜ ë‹µë³€ë§Œ ì¶”ì¶œ
    response_only = tokenizer.decode(outputs[0][raw_inputs['input_ids'].shape[-1]:], skip_special_tokens=True)
    
    return response_only

# --- 4. Streamlit UI ë° ë©”ì¸ ë¡œì§ ---
st.title("AI ìœ¡ì•„ ë„ìš°ë¯¸ ë´‡ ğŸ¤–")
st.info("ì„ì‹ , ì¶œì‚°, ìœ¡ì•„ ì§ˆë¬¸ì€ ë¬¼ë¡ , 'ë¶€ì²œ ì›ì¢…ë™ ì£¼ë³€ ì†Œì•„ê³¼ ì°¾ì•„ì¤˜'ì²˜ëŸ¼ ì¥ì†Œ ê²€ìƒ‰ë„ ê°€ëŠ¥í•´ìš”!")

st.sidebar.title("ë©”ë‰´")
st.sidebar.info("ì´ê³³ì— ì¶”ê°€ ì •ë³´ë‚˜ ë§í¬ë¥¼ ë„£ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.rerun()

if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    with st.chat_message("assistant"):
        with st.spinner("AIê°€ ì—´ì‹¬íˆ ìƒê°í•˜ê³  ìˆì–´ìš”... ğŸ¤”"):
            user_prompt = st.session_state.messages[-1]["content"] # ìµœì‹  í”„ë¡¬í”„íŠ¸ëŠ” ì˜ë„ íŒŒì•…ì— ì‚¬ìš©
            intent = parse_intent_with_ai(user_prompt)
            action = intent.get("action", "chat")

            if action == "search":
                response_content = handle_search(intent)
            else:
                response_content = ask_rag(st.session_state.messages)

            st.session_state.messages.append({"role": "assistant", "content": response_content})
            st.rerun()

# --- CSS ìŠ¤íƒ€ì¼ë§ ë° ì´ë¯¸ì§€ ì˜¤ë²„ë ˆì´ ì½”ë“œ ---
st.markdown("""
<style>
/* === ê¸°ë³¸ í°íŠ¸/ìƒ‰ í† í° === */
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;600;700&display=swap');
:root{
  --brand:#6C7CFF;
  --bg:#F7F9FC;
  --surface:#FFFFFF;
  --line:#E9EEF5;
  --text:#111827;
  --radius:12px;
  --radius-lg:16px;
  --font:'Noto Sans KR', system-ui, -apple-system, Segoe UI, Roboto, sans-serif;
}
@media (prefers-color-scheme: dark){
  :root{ --bg:#0B1220; --surface:#0F1629; --line:#1E2A44; --text:#E5E7EB; }
}
body, div, p, span, h1, h2, h3, h4, h5, h6{ font-family:var(--font); }

/* === ë°°ê²½/ë ˆì´ì•„ì›ƒ ìµœì†Œ === */
.main{
  background:
    radial-gradient(1200px 600px at 10% -10%, rgba(108,124,255,.06) 0%, rgba(108,124,255,0) 50%),
    linear-gradient(180deg, var(--bg) 0%, var(--surface) 64%);
}
section.main > div.block-container{ padding-top:1rem; padding-bottom:1.4rem; }

/* ëª¨ì…˜ ìµœì†Œí™” ì¡´ì¤‘ */
@media (prefers-reduced-motion: reduce){ *{animation:none !important; transition:none !important;} }

/* === íƒ€ì´í‹€ë§Œ ê°€ë³ê²Œ === */
.block-container h1:first-of-type{
  margin-bottom:.35rem; font-weight:800; letter-spacing:-.2px;
  background:linear-gradient(90deg, var(--text), color-mix(in oklab, var(--text), #334155 60%));
  -webkit-background-clip:text; background-clip:text; color:transparent;
}

/* === ì´ë¯¸ì§€ ê³µí†µ(ê·¸ë¦¼ì/í…Œë‘ë¦¬ ì œê±°) === */
[data-testid="stImage"] img{
  display:block; width:100%; height:auto; max-height:42vh; object-fit:cover;
  border-radius:var(--radius-lg); box-shadow:none !important; border:none !important; background:transparent !important;
}

/* === ì±„íŒ… ì…ë ¥ì°½ ìµœì†Œ === */
[data-testid="stChatInput"]{ border-top:1px dashed var(--line); padding-top:.6rem; margin-top:.6rem; }
[data-testid="stChatInput"] textarea{
  border:1px solid var(--line) !important; border-radius:var(--radius) !important; box-shadow:0 2px 10px rgba(0,0,0,.03) !important;
}

/* === íˆì–´ë¡œ ì´ë¯¸ì§€ ìœ„ì¹˜(ì¢Œìƒ/ìš°í•˜) === */
.hero-left, .hero-right{
  position:fixed; max-width:none !important; height:auto; object-fit:contain;
  border-radius:12px; box-shadow:none !important; border:none !important; background:transparent !important; pointer-events:none; z-index:0;
}
.hero-left{ top:120px; left:48px; width:220px; }
.hero-right{ top:360px; right:48px; width:240px; }


@media (max-width: 900px){ .hero-left, .hero-right{ display:none; } }
@media (max-width: 640px){ [data-testid="stImage"] img{ max-height:32vh; } }
</style>
""", unsafe_allow_html=True)

def image_to_data_uri(path):
    if not os.path.exists(path):
        return ""
    try:
        import base64
        with open(path, "rb") as f:
            encoded = base64.b64encode(f.read()).decode()
        return f"data:image/png;base64,{encoded}"
    except Exception:
        return ""

left_uri = image_to_data_uri("1.png")
right_uri = image_to_data_uri("2.png")
if left_uri:
    st.markdown(f'<img class="hero-left" src="{left_uri}" alt="left decoration">', unsafe_allow_html=True)
if right_uri:
    st.markdown(f'<img class="hero-right" src="{right_uri}" alt="right decoration">', unsafe_allow_html=True)
